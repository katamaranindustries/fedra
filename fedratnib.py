# -*- coding: utf-8 -*-
"""fedratnib.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yaXoVX3S6slfwRr8_YowwbDUQBy_tNN1
"""

-import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score

df=pd.read_csv('fedratnib.csv')

df.info()



categorical_cols = ['Cell line', 'TCGA classification', 'Tissue', 'Tissue sub-type']
le = LabelEncoder()
for col in categorical_cols:
    df[col] = le.fit_transform(df[col])

df['Response'] = df['IC50'] < 500

X = df.drop(['IC50', 'Response'], axis=1)
y = df['Response']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)
rf_pred = rf.predict(X_test)
rf_acc = accuracy_score(y_test, rf_pred)



gb = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)
gb.fit(X_train, y_train)
gb_pred = gb.predict(X_test)
gb_acc = accuracy_score(y_test, gb_pred)

accuracy_matrix = [[rf_acc, gb_acc]]
model_names = ['Random Forest', 'Gradient Boosting']
accuracy_df = pd.DataFrame(accuracy_matrix, columns=model_names)

plt.figure(figsize=(8, 4))
sns.heatmap(accuracy_df, annot=True, cmap='coolwarm', linewidths=0.5, fmt=".2f", cbar=False)
plt.title('Model Accuracy Heatmap')
plt.xlabel('Models')
plt.ylabel('Accuracy')
plt.show()



plt.figure(figsize=(8, 6))
plt.scatter(df['AUC'], df['IC50'])
plt.xlabel('AUC')
plt.ylabel('IC50')
plt.title('Scatter Plot: AUC vs IC50')
plt.show()

plt.figure(figsize=(8, 6))
plt.scatter(df['Cell line'], df['IC50'])
plt.xlabel('Cell Line')
plt.ylabel('IC50')
plt.title('Scatter Plot: Cell Line vs IC50')
plt.show()



# Assuming 'df' is your DataFrame containing numerical columns
numerical_cols = df.select_dtypes(include=['number']).columns.tolist()

# Loop through numerical columns to detect and remove outliers
for col in numerical_cols:
    Q1 = df[col].quantile(0.25)
    Q3 = df[col].quantile(0.75)
    IQR = Q3 - Q1

    # Define the boundaries to identify outliers
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR

    # Filter and remove outliers
    df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]